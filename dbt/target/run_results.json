{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.10.13", "generated_at": "2026-01-08T10:38:51.660382Z", "invocation_id": "302cd842-b611-46d5-9b41-edaf36bf90e4", "invocation_started_at": "2026-01-08T10:38:46.134847Z", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:48.554449Z", "completed_at": "2026-01-08T10:38:48.563653Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:48.564052Z", "completed_at": "2026-01-08T10:38:48.666576Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.11391067504882812, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.stg_jobs_raw", "compiled": true, "compiled_code": "-- models/bronze/stg_jobs_raw.sql\n-- Bronze layer: Lecture directe des donn\u00e9es brutes depuis final_data.csv\n-- Renommage et typage minimal\n\n\n\n-- Read directly from CSV file\nSELECT\n    -- Renommer les colonnes pour coh\u00e9rence\n    title as job_title,\n    location,\n    postedTime as posted_time,\n    publishedAt as published_at,\n    jobUrl as job_url,\n    companyName as company_name,\n    companyUrl as company_url,\n    description as job_description,\n    contractType as contract_type,\n    workType as work_type,\n    \n    -- M\u00e9tadonn\u00e9es de tra\u00e7abilit\u00e9\n    NOW() as ingestion_timestamp,\n    '2026-01-08 10:38:46.135216+00:00' as dbt_run_id\n\nFROM read_csv_auto('D:/lab2/final_data.csv')\n\nWHERE 1=1\n    -- Filtrer les lignes vides\n    AND title IS NOT NULL\n    AND description IS NOT NULL", "relation_name": "\"duckdb\".\"main_bronze\".\"stg_jobs_raw\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:48.672621Z", "completed_at": "2026-01-08T10:38:48.676948Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:48.677605Z", "completed_at": "2026-01-08T10:38:48.928916Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.25835514068603516, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.int_jobs_cleaned", "compiled": true, "compiled_code": "-- models/silver/int_jobs_cleaned.sql\n-- Silver layer: Nettoyage et normalisation des donn\u00e9es brutes\n\n\n\nWITH raw_jobs AS (\n    SELECT * FROM \"duckdb\".\"main_bronze\".\"stg_jobs_raw\"\n),\n\ncleaned_jobs AS (\n    SELECT\n        -- Texte: lowercase, trim, remove special characters\n        LOWER(TRIM(job_title)) as job_title_cleaned,\n        LOWER(TRIM(location)) as location_cleaned,\n        LOWER(TRIM(company_name)) as company_name_cleaned,\n        LOWER(TRIM(job_description)) as job_description_cleaned,\n        LOWER(TRIM(contract_type)) as contract_type_cleaned,\n        LOWER(TRIM(work_type)) as work_type_cleaned,\n        \n        -- URLs as-is\n        job_url,\n        company_url,\n        \n        -- Dates\n        TRY_CAST(published_at AS DATE) as published_date,\n        posted_time,\n        \n        -- Extract year-month for time-based analysis\n        DATE_TRUNC('month', TRY_CAST(published_at AS DATE)) as published_year_month,\n        EXTRACT(YEAR FROM TRY_CAST(published_at AS DATE)) as published_year,\n        EXTRACT(MONTH FROM TRY_CAST(published_at AS DATE)) as published_month,\n        \n        -- M\u00e9tadonn\u00e9es\n        ingestion_timestamp\n    FROM raw_jobs\n)\n\nSELECT\n    *,\n    -- Deduplication flag\n    ROW_NUMBER() OVER (\n        PARTITION BY job_title_cleaned, company_name_cleaned, location_cleaned \n        ORDER BY published_date DESC\n    ) as dedup_rank\nFROM cleaned_jobs", "relation_name": "\"duckdb\".\"main_silver\".\"int_jobs_cleaned\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:48.939751Z", "completed_at": "2026-01-08T10:38:48.949296Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:48.950312Z", "completed_at": "2026-01-08T10:38:49.060872Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.12425804138183594, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.int_job_title_normalization", "compiled": true, "compiled_code": "-- models/silver/int_job_title_normalization.sql\n-- Silver layer: Normaliser les intitul\u00e9s de postes\n\n\n\nWITH cleaned_jobs AS (\n    SELECT * FROM \"duckdb\".\"main_silver\".\"int_jobs_cleaned\"\n),\n\ntitle_normalized AS (\n    SELECT\n        *,\n        CASE\n            WHEN job_title_cleaned LIKE '%data engineer%' THEN 'Data Engineer'\n            WHEN job_title_cleaned LIKE '%data scientist%' THEN 'Data Scientist'\n            WHEN job_title_cleaned LIKE '%data analyst%' THEN 'Data Analyst'\n            WHEN job_title_cleaned LIKE '%analytics engineer%' THEN 'Analytics Engineer'\n            WHEN job_title_cleaned LIKE '%ml engineer%' OR job_title_cleaned LIKE '%machine learning%' THEN 'ML Engineer'\n            WHEN job_title_cleaned LIKE '%data architect%' THEN 'Data Architect'\n            WHEN job_title_cleaned LIKE '%bi developer%' OR job_title_cleaned LIKE '%business intelligence%' THEN 'BI Developer'\n            WHEN job_title_cleaned LIKE '%etl%' OR job_title_cleaned LIKE '%pipeline%' THEN 'ETL/Pipeline Engineer'\n            WHEN job_title_cleaned LIKE '%data engineer%' THEN 'Data Engineer'\n            ELSE 'Other Data Role'\n        END as job_category,\n        \n        CASE\n            WHEN contract_type_cleaned LIKE '%cdi%' OR contract_type_cleaned LIKE '%permanent%' THEN 'Permanent'\n            WHEN contract_type_cleaned LIKE '%cdd%' OR contract_type_cleaned LIKE '%contract%' THEN 'Contract'\n            WHEN contract_type_cleaned LIKE '%stage%' OR contract_type_cleaned LIKE '%internship%' THEN 'Internship'\n            WHEN contract_type_cleaned LIKE '%freelance%' THEN 'Freelance'\n            ELSE 'Not Specified'\n        END as contract_type_normalized,\n        \n        CASE\n            WHEN work_type_cleaned LIKE '%remote%' THEN 'Remote'\n            WHEN work_type_cleaned LIKE '%hybrid%' THEN 'Hybrid'\n            WHEN work_type_cleaned LIKE '%onsite%' OR work_type_cleaned LIKE '%on-site%' THEN 'On-site'\n            ELSE 'Not Specified'\n        END as work_type_normalized\n    \n    FROM cleaned_jobs\n    WHERE dedup_rank = 1  -- Keep only first occurrence (most recent)\n)\n\nSELECT * FROM title_normalized", "relation_name": "\"duckdb\".\"main_silver\".\"int_job_title_normalization\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:49.070365Z", "completed_at": "2026-01-08T10:38:49.088976Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:49.093437Z", "completed_at": "2026-01-08T10:38:49.230710Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.16235041618347168, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.dim_time", "compiled": true, "compiled_code": "-- models/gold/dim_time.sql\n-- Gold layer: Dimension Time\n\n\n\n-- Generate a date dimension for time-based analysis\nWITH date_spine AS (\n    SELECT\n        published_date,\n        EXTRACT(YEAR FROM published_date) as year,\n        EXTRACT(MONTH FROM published_date) as month,\n        EXTRACT(QUARTER FROM published_date) as quarter,\n        EXTRACT(WEEK FROM published_date) as week,\n        EXTRACT(DAYOFWEEK FROM published_date) as day_of_week,\n        DATE_TRUNC('month', published_date) as month_start,\n        DATE_TRUNC('quarter', published_date) as quarter_start,\n        DATE_TRUNC('year', published_date) as year_start,\n        \n        CASE \n            WHEN EXTRACT(MONTH FROM published_date) IN (1,2,3) THEN 'Q1'\n            WHEN EXTRACT(MONTH FROM published_date) IN (4,5,6) THEN 'Q2'\n            WHEN EXTRACT(MONTH FROM published_date) IN (7,8,9) THEN 'Q3'\n            ELSE 'Q4'\n        END as quarter_name,\n        \n        CASE EXTRACT(DAYOFWEEK FROM published_date)\n            WHEN 0 THEN 'Sunday'\n            WHEN 1 THEN 'Monday'\n            WHEN 2 THEN 'Tuesday'\n            WHEN 3 THEN 'Wednesday'\n            WHEN 4 THEN 'Thursday'\n            WHEN 5 THEN 'Friday'\n            WHEN 6 THEN 'Saturday'\n        END as day_name,\n        \n        CASE EXTRACT(MONTH FROM published_date)\n            WHEN 1 THEN 'January'\n            WHEN 2 THEN 'February'\n            WHEN 3 THEN 'March'\n            WHEN 4 THEN 'April'\n            WHEN 5 THEN 'May'\n            WHEN 6 THEN 'June'\n            WHEN 7 THEN 'July'\n            WHEN 8 THEN 'August'\n            WHEN 9 THEN 'September'\n            WHEN 10 THEN 'October'\n            WHEN 11 THEN 'November'\n            WHEN 12 THEN 'December'\n        END as month_name\n        \n    FROM (\n        SELECT DISTINCT published_date\n        FROM \"duckdb\".\"main_silver\".\"int_job_title_normalization\"\n        WHERE published_date IS NOT NULL\n    )\n)\n\nSELECT\n    published_date as date_id,\n    year,\n    month,\n    quarter,\n    week,\n    day_of_week,\n    day_name,\n    month_name,\n    quarter_name,\n    month_start,\n    quarter_start,\n    year_start,\n    NOW() as created_at\nFROM date_spine\nORDER BY published_date", "relation_name": "\"duckdb\".\"main_gold\".\"dim_time\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:49.101998Z", "completed_at": "2026-01-08T10:38:49.127975Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:49.129558Z", "completed_at": "2026-01-08T10:38:49.238074Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.1538553237915039, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.dim_company", "compiled": true, "compiled_code": "-- models/gold/dim_company.sql\n-- Gold layer: Dimension Company\n\n\n\nWITH jobs AS (\n    SELECT DISTINCT\n        company_name_cleaned,\n        company_url\n    FROM \"duckdb\".\"main_silver\".\"int_job_title_normalization\"\n    WHERE company_name_cleaned IS NOT NULL\n),\n\nranked_companies AS (\n    SELECT\n        ROW_NUMBER() OVER (ORDER BY company_name_cleaned) as company_id,\n        company_name_cleaned as company_name,\n        company_url,\n        NOW() as created_at\n    FROM jobs\n)\n\nSELECT\n    company_id,\n    company_name,\n    company_url,\n    created_at\nFROM ranked_companies\nORDER BY company_id", "relation_name": "\"duckdb\".\"main_gold\".\"dim_company\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:49.110612Z", "completed_at": "2026-01-08T10:38:49.140925Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:49.145371Z", "completed_at": "2026-01-08T10:38:49.241752Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.15443038940429688, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.dim_location", "compiled": true, "compiled_code": "-- models/gold/dim_location.sql\n-- Gold layer: Dimension Location\n\n\n\nWITH jobs AS (\n    SELECT DISTINCT\n        location_cleaned as location_raw\n    FROM \"duckdb\".\"main_silver\".\"int_job_title_normalization\"\n    WHERE location_cleaned IS NOT NULL\n),\n\nlocation_parsed AS (\n    SELECT\n        location_raw,\n        -- Extract city (before comma)\n        CASE \n            WHEN POSITION(',' IN location_raw) > 0 \n            THEN TRIM(SUBSTRING(location_raw, 1, POSITION(',' IN location_raw) - 1))\n            ELSE location_raw\n        END as city,\n        \n        -- Extract country (after comma)\n        CASE \n            WHEN POSITION(',' IN location_raw) > 0 \n            THEN TRIM(SUBSTRING(location_raw, POSITION(',' IN location_raw) + 1))\n            ELSE 'Not Specified'\n        END as country,\n        \n        -- Detect if remote\n        CASE \n            WHEN location_raw LIKE '%remote%' \n            THEN 'Remote'\n            ELSE 'On-site'\n        END as work_location_type\n    FROM jobs\n),\n\nranked_locations AS (\n    SELECT\n        ROW_NUMBER() OVER (ORDER BY location_raw) as location_id,\n        location_raw,\n        city,\n        country,\n        work_location_type,\n        NOW() as created_at\n    FROM location_parsed\n)\n\nSELECT\n    location_id,\n    location_raw,\n    city,\n    country,\n    work_location_type,\n    created_at\nFROM ranked_locations\nORDER BY location_id", "relation_name": "\"duckdb\".\"main_gold\".\"dim_location\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:49.246445Z", "completed_at": "2026-01-08T10:38:49.250931Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:49.251385Z", "completed_at": "2026-01-08T10:38:49.433498Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.18851542472839355, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.fact_job_offers", "compiled": true, "compiled_code": "-- models/gold/fact_job_offers.sql\n-- Gold layer: Fact Table - Job Offers (Sch\u00e9ma en \u00c9toile)\n\n\n\nWITH jobs AS (\n    SELECT\n        j.*\n    FROM \"duckdb\".\"main_silver\".\"int_job_title_normalization\" j\n),\n\ncompanies AS (\n    SELECT * FROM \"duckdb\".\"main_gold\".\"dim_company\"\n),\n\nlocations AS (\n    SELECT * FROM \"duckdb\".\"main_gold\".\"dim_location\"\n),\n\ntimes AS (\n    SELECT * FROM \"duckdb\".\"main_gold\".\"dim_time\"\n),\n\nfact_table AS (\n    SELECT\n        -- Surrogate keys\n        ROW_NUMBER() OVER (ORDER BY j.job_url, j.company_name_cleaned) as job_offer_id,\n        \n        -- Foreign keys\n        c.company_id,\n        l.location_id,\n        t.date_id as published_date_id,\n        \n        -- Job dimensions\n        j.job_title_cleaned as job_title,\n        j.job_category,\n        j.contract_type_normalized as contract_type,\n        j.work_type_normalized as work_type,\n        \n        -- URLs\n        j.job_url,\n        j.company_url,\n        \n        -- Description\n        j.job_description_cleaned as job_description,\n        \n        -- Time dimension\n        j.published_date,\n        j.posted_time,\n        j.published_year_month,\n        j.published_year,\n        j.published_month,\n        \n        -- Metrics\n        LENGTH(j.job_description_cleaned) as description_length,\n        (LENGTH(j.job_description_cleaned) - LENGTH(REPLACE(j.job_description_cleaned, ' ', ''))) + 1 as word_count,\n        \n        -- Flags\n        CASE WHEN j.work_type_normalized = 'Remote' THEN 1 ELSE 0 END as is_remote,\n        CASE WHEN j.contract_type_normalized = 'Permanent' THEN 1 ELSE 0 END as is_permanent,\n        \n        -- Metadata\n        NOW() as created_at,\n        j.ingestion_timestamp\n        \n    FROM jobs j\n    LEFT JOIN companies c ON j.company_name_cleaned = c.company_name\n    LEFT JOIN locations l ON j.location_cleaned = l.location_raw\n    LEFT JOIN times t ON j.published_date = t.date_id\n)\n\nSELECT\n    job_offer_id,\n    company_id,\n    location_id,\n    published_date_id,\n    job_title,\n    job_category,\n    contract_type,\n    work_type,\n    job_url,\n    company_url,\n    job_description,\n    published_date,\n    posted_time,\n    published_year_month,\n    published_year,\n    published_month,\n    description_length,\n    word_count,\n    is_remote,\n    is_permanent,\n    created_at,\n    ingestion_timestamp\nFROM fact_table\nORDER BY published_date DESC, job_offer_id", "relation_name": "\"duckdb\".\"main_gold\".\"fact_job_offers\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:49.440625Z", "completed_at": "2026-01-08T10:38:49.448577Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:49.449039Z", "completed_at": "2026-01-08T10:38:49.495847Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.05765581130981445, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.agg_job_offers_by_category_time", "compiled": true, "compiled_code": "-- models/gold/agg_job_offers_by_category_time.sql\n-- Gold layer: Aggregate - Job Offers by Category and Time\n\n\n\nSELECT\n    f.published_year,\n    f.published_month,\n    f.published_year_month,\n    f.job_category,\n    f.contract_type,\n    f.work_type,\n    \n    COUNT(DISTINCT f.job_offer_id) as count_job_offers,\n    COUNT(DISTINCT f.company_id) as count_companies,\n    \n    AVG(f.description_length) as avg_description_length,\n    AVG(f.word_count) as avg_word_count,\n    \n    SUM(CASE WHEN f.is_remote = 1 THEN 1 ELSE 0 END) as remote_jobs,\n    SUM(CASE WHEN f.is_permanent = 1 THEN 1 ELSE 0 END) as permanent_jobs,\n    \n    NOW() as created_at\n    \nFROM \"duckdb\".\"main_gold\".\"fact_job_offers\" f\nWHERE f.published_date IS NOT NULL\nGROUP BY\n    f.published_year,\n    f.published_month,\n    f.published_year_month,\n    f.job_category,\n    f.contract_type,\n    f.work_type\nORDER BY f.published_year_month DESC, f.job_category", "relation_name": "\"duckdb\".\"main_gold\".\"agg_job_offers_by_category_time\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:49.444828Z", "completed_at": "2026-01-08T10:38:49.451777Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:49.452366Z", "completed_at": "2026-01-08T10:38:49.507149Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.06846046447753906, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.agg_location_analysis", "compiled": true, "compiled_code": "-- models/gold/agg_location_analysis.sql\n-- Gold layer: Aggregate - Location Analysis\n\n\n\nSELECT\n    dl.location_id,\n    dl.location_raw,\n    dl.city,\n    dl.country,\n    dl.work_location_type,\n    \n    COUNT(DISTINCT f.job_offer_id) as count_job_offers,\n    COUNT(DISTINCT f.company_id) as count_companies,\n    \n    -- Distribution by job category\n    COUNT(DISTINCT CASE WHEN f.job_category = 'Data Engineer' THEN f.job_offer_id END) as data_engineer_count,\n    COUNT(DISTINCT CASE WHEN f.job_category = 'Data Scientist' THEN f.job_offer_id END) as data_scientist_count,\n    COUNT(DISTINCT CASE WHEN f.job_category = 'Data Analyst' THEN f.job_offer_id END) as data_analyst_count,\n    COUNT(DISTINCT CASE WHEN f.job_category = 'ML Engineer' THEN f.job_offer_id END) as ml_engineer_count,\n    \n    -- Remote percentage\n    ROUND(\n        100.0 * SUM(CASE WHEN f.is_remote = 1 THEN 1 ELSE 0 END) / COUNT(DISTINCT f.job_offer_id),\n        2\n    ) as pct_remote,\n    \n    NOW() as created_at\n    \nFROM \"duckdb\".\"main_gold\".\"dim_location\" dl\nLEFT JOIN \"duckdb\".\"main_gold\".\"fact_job_offers\" f ON dl.location_id = f.location_id\nGROUP BY\n    dl.location_id,\n    dl.location_raw,\n    dl.city,\n    dl.country,\n    dl.work_location_type\nORDER BY count_job_offers DESC", "relation_name": "\"duckdb\".\"main_gold\".\"agg_location_analysis\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:49.119980Z", "completed_at": "2026-01-08T10:38:49.142025Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:49.152941Z", "completed_at": "2026-01-08T10:38:51.144683Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.0541372299194336, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.int_skills_extraction", "compiled": true, "compiled_code": "-- models/silver/int_skills_extraction.sql\n-- Silver layer: Extraction des comp\u00e9tences depuis la description\n\n\n\nWITH jobs_with_titles AS (\n    SELECT * FROM \"duckdb\".\"main_silver\".\"int_job_title_normalization\"\n),\n\nskills_mapping AS (\n    -- D\u00e9finir un mapping de comp\u00e9tences communes Data/Tech\n    SELECT\n        'Python' as skill_name,\n        'python|py |\\.py' as skill_pattern\n    UNION ALL SELECT 'SQL', 'sql|sql|sql server|postgres|oracle'\n    UNION ALL SELECT 'Spark', 'spark|pyspark'\n    UNION ALL SELECT 'Hadoop', 'hadoop|hdfs'\n    UNION ALL SELECT 'Scala', 'scala'\n    UNION ALL SELECT 'Java', '\\bjava\\b'\n    UNION ALL SELECT 'R', '\\br\\b|r programming'\n    UNION ALL SELECT 'Tableau', 'tableau'\n    UNION ALL SELECT 'Power BI', 'power bi|powerbi'\n    UNION ALL SELECT 'Looker', 'looker'\n    UNION ALL SELECT 'AWS', 'aws|amazon web|s3 |ec2|redshift'\n    UNION ALL SELECT 'Azure', 'azure|microsoft azure|synapse|cosmos'\n    UNION ALL SELECT 'GCP', 'gcp|google cloud|bigquery'\n    UNION ALL SELECT 'Airflow', 'airflow'\n    UNION ALL SELECT 'DBT', '\\bdbt\\b|dbt'\n    UNION ALL SELECT 'Kubernetes', 'kubernetes|k8s'\n    UNION ALL SELECT 'Docker', 'docker'\n    UNION ALL SELECT 'Git', 'git|github|gitlab'\n    UNION ALL SELECT 'TensorFlow', 'tensorflow'\n    UNION ALL SELECT 'PyTorch', 'pytorch'\n    UNION ALL SELECT 'Scikit-learn', 'scikit|sklearn'\n    UNION ALL SELECT 'Pandas', 'pandas'\n    UNION ALL SELECT 'NumPy', 'numpy'\n    UNION ALL SELECT 'Machine Learning', 'machine learning|deep learning|ml|artificial intelligence'\n    UNION ALL SELECT 'Statistics', 'statistics|statistical|probability'\n    UNION ALL SELECT 'Data Visualization', 'data visualization|visualization|charts|graphs'\n),\n\njobs_exploded AS (\n    SELECT\n        j.*,\n        s.skill_name,\n        CASE \n            WHEN job_description_cleaned ILIKE '%' || s.skill_pattern || '%' THEN 1 \n            ELSE 0 \n        END as has_skill\n    FROM jobs_with_titles j\n    CROSS JOIN skills_mapping s\n)\n\nSELECT\n    *\nFROM jobs_exploded\nWHERE has_skill = 1\n\nORDER BY job_title_cleaned, published_date DESC", "relation_name": "\"duckdb\".\"main_silver\".\"int_skills_extraction\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:51.149371Z", "completed_at": "2026-01-08T10:38:51.153472Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:51.153914Z", "completed_at": "2026-01-08T10:38:51.537368Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.38966941833496094, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.dim_skills", "compiled": true, "compiled_code": "-- models/gold/dim_skills.sql\n-- Gold layer: Dimension Skills\n\n\n\nWITH skills AS (\n    SELECT DISTINCT\n        skill_name\n    FROM \"duckdb\".\"main_silver\".\"int_skills_extraction\"\n    WHERE skill_name IS NOT NULL\n),\n\nskill_categorization AS (\n    SELECT\n        skill_name,\n        CASE\n            WHEN skill_name IN ('Python', 'Java', 'Scala', 'R') THEN 'Programming Language'\n            WHEN skill_name IN ('SQL', 'NoSQL') THEN 'Database'\n            WHEN skill_name IN ('Spark', 'Hadoop', 'Hive', 'Kafka') THEN 'Big Data Framework'\n            WHEN skill_name IN ('TensorFlow', 'PyTorch', 'Scikit-learn') THEN 'ML/DL Library'\n            WHEN skill_name IN ('AWS', 'Azure', 'GCP') THEN 'Cloud Platform'\n            WHEN skill_name IN ('Tableau', 'Power BI', 'Looker') THEN 'BI Tool'\n            WHEN skill_name IN ('Airflow', 'DBT', 'Kubernetes', 'Docker') THEN 'DataOps/DevOps'\n            WHEN skill_name IN ('Pandas', 'NumPy', 'Matplotlib') THEN 'Data Analysis Library'\n            WHEN skill_name IN ('Machine Learning', 'Statistics', 'Data Visualization') THEN 'Domain Knowledge'\n            ELSE 'Other'\n        END as skill_category\n    FROM skills\n),\n\nranked_skills AS (\n    SELECT\n        ROW_NUMBER() OVER (ORDER BY skill_name) as skill_id,\n        skill_name,\n        skill_category,\n        NOW() as created_at\n    FROM skill_categorization\n)\n\nSELECT\n    skill_id,\n    skill_name,\n    skill_category,\n    created_at\nFROM ranked_skills\nORDER BY skill_id", "relation_name": "\"duckdb\".\"main_gold\".\"dim_skills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:51.543785Z", "completed_at": "2026-01-08T10:38:51.548887Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:51.549364Z", "completed_at": "2026-01-08T10:38:51.591832Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.04998302459716797, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.fact_job_skills", "compiled": true, "compiled_code": "-- models/gold/fact_job_skills.sql\n-- Gold layer: Bridge Table - Job Skills\n\n\n\nWITH skills_raw AS (\n    SELECT DISTINCT\n        job_url,\n        company_name_cleaned,\n        skill_name\n    FROM \"duckdb\".\"main_silver\".\"int_skills_extraction\"\n),\n\njobs AS (\n    SELECT\n        job_offer_id,\n        job_url\n    FROM \"duckdb\".\"main_gold\".\"fact_job_offers\"\n),\n\nskills_dim AS (\n    SELECT\n        skill_id,\n        skill_name\n    FROM \"duckdb\".\"main_gold\".\"dim_skills\"\n),\n\nfact_table AS (\n    SELECT\n        ROW_NUMBER() OVER (ORDER BY s.job_url, sd.skill_id) as job_skill_id,\n        j.job_offer_id,\n        sd.skill_id,\n        s.skill_name,\n        NOW() as created_at\n    FROM skills_raw s\n    LEFT JOIN jobs j ON s.job_url = j.job_url\n    LEFT JOIN skills_dim sd ON s.skill_name = sd.skill_name\n)\n\nSELECT\n    job_skill_id,\n    job_offer_id,\n    skill_id,\n    skill_name,\n    created_at\nFROM fact_table\nWHERE job_offer_id IS NOT NULL\nORDER BY job_offer_id, skill_id", "relation_name": "\"duckdb\".\"main_gold\".\"fact_job_skills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-08T10:38:51.598700Z", "completed_at": "2026-01-08T10:38:51.605095Z"}, {"name": "execute", "started_at": "2026-01-08T10:38:51.605683Z", "completed_at": "2026-01-08T10:38:51.646928Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.049989938735961914, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.job_intelligent.agg_skills_demand", "compiled": true, "compiled_code": "-- models/gold/agg_skills_demand.sql\n-- Gold layer: Aggregate - Skills in Demand\n\n\n\nSELECT\n    sd.skill_id,\n    sd.skill_name,\n    sd.skill_category,\n    \n    COUNT(DISTINCT fs.job_offer_id) as count_jobs_requiring_skill,\n    COUNT(DISTINCT f.company_id) as count_companies_requiring_skill,\n    \n    -- Percentage of all jobs\n    ROUND(\n        100.0 * COUNT(DISTINCT fs.job_offer_id) / (\n            SELECT COUNT(DISTINCT job_offer_id) FROM \"duckdb\".\"main_gold\".\"fact_job_offers\"\n        ),\n        2\n    ) as pct_of_total_jobs,\n    \n    -- Average job details for jobs requiring this skill\n    AVG(f.description_length) as avg_description_length,\n    AVG(f.word_count) as avg_word_count,\n    \n    NOW() as created_at\n    \nFROM \"duckdb\".\"main_gold\".\"dim_skills\" sd\nLEFT JOIN \"duckdb\".\"main_gold\".\"fact_job_skills\" fs ON sd.skill_id = fs.skill_id\nLEFT JOIN \"duckdb\".\"main_gold\".\"fact_job_offers\" f ON fs.job_offer_id = f.job_offer_id\nGROUP BY\n    sd.skill_id,\n    sd.skill_name,\n    sd.skill_category\nORDER BY count_jobs_requiring_skill DESC", "relation_name": "\"duckdb\".\"main_gold\".\"agg_skills_demand\"", "batch_results": null}], "elapsed_time": 3.4980688095092773, "args": {"log_level": "info", "log_path": "D:\\lab2\\dbt_project\\logs", "require_batched_execution_for_custom_microbatch_strategy": false, "strict_mode": false, "log_format_file": "debug", "quiet": false, "use_colors": true, "populate_cache": true, "state_modified_compare_vars": false, "source_freshness_run_project_hooks": true, "skip_nodes_if_on_run_start_fails": false, "partial_parse": true, "require_all_warnings_handled_by_warn_error": false, "partial_parse_file_diff": true, "profiles_dir": "D:\\lab2\\dbt_project", "validate_macro_args": false, "introspect": true, "show_resource_report": false, "upload_to_artifacts_ingest_api": false, "use_fast_test_edges": false, "warn_error_options": {"error": [], "warn": [], "silence": []}, "require_yaml_configuration_for_mf_time_spines": false, "static_parser": true, "require_explicit_package_overrides_for_builtin_materializations": true, "use_colors_file": true, "cache_selected_only": false, "require_generic_test_arguments_property": true, "which": "run", "show_all_deprecations": false, "version_check": true, "select": [], "write_json": true, "invocation_command": "dbt run", "log_level_file": "debug", "send_anonymous_usage_stats": true, "state_modified_compare_more_unrendered_values": false, "exclude": [], "empty": false, "require_resource_names_without_spaces": true, "project_dir": "D:\\lab2\\dbt_project", "favor_state": false, "log_format": "default", "require_nested_cumulative_type_params": false, "vars": {}, "macro_debugging": false, "print": true, "log_file_max_bytes": 10485760, "indirect_selection": "eager", "defer": false, "printer_width": 80}}